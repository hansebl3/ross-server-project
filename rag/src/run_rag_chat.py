import requests
import json
import chromadb
from sentence_transformers import SentenceTransformer
import sys
import os

# --- ì„¤ì • ---
OLLAMA_URL = "http://100.65.53.9:11434/api/chat"
CHROMA_HOST = '100.65.53.9'
CHROMA_PORT = 8001
EMBED_MODEL_ID = 'jhgan/ko-sroberta-multitask'
COLLECTION_NAME = "factory_manuals"
LLM_MODEL = "gpt-oss:20b" 

class RAGChat:
    def __init__(self):
        print("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print(f"   - ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {EMBED_MODEL_ID}")
        try:
            self.embed_model = SentenceTransformer(EMBED_MODEL_ID)
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            sys.exit(1)

        # 2. ChromaDB ì—°ê²°
        print(f"   - ChromaDB ì—°ê²°: {CHROMA_HOST}:{CHROMA_PORT}")
        try:
            self.db_client = chromadb.HttpClient(host=CHROMA_HOST, port=CHROMA_PORT)
            self.collection = self.db_client.get_collection(name=COLLECTION_NAME)
            count = self.collection.count()
            print(f"   âœ… ì—°ê²° ì„±ê³µ! (ì €ì¥ëœ ë¬¸ì„œ: {count}ê°œ)")
        except Exception as e:
            print(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
            print("   DBê°€ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)

    def search(self, query, k=3):
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ Top-k ê²€ìƒ‰"""
        vec = self.embed_model.encode(query).tolist()
        res = self.collection.query(query_embeddings=[vec], n_results=k)
        
        documents = res['documents'][0]
        distances = res['distances'][0]
        
        return documents, distances

    def chat(self, user_input):
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        print(f"\nğŸ” DB ê²€ìƒ‰ ì¤‘...", end="", flush=True)
        docs, dists = self.search(user_input)
        print(" ì™„ë£Œ.")

        if not docs:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê²€ìƒ‰ëœ ë‚´ìš© ì¡°í•©
        context = "\n".join([f"- {doc}" for doc in docs])
        
        # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        # 2-1. system.txtì—ì„œ ì¶”ê°€ ì§€ì‹œì‚¬í•­ ì½ê¸°
        custom_instructions = ""
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            system_file_path = os.path.join(script_dir, 'system.txt')
            if os.path.exists(system_file_path):
                with open(system_file_path, 'r', encoding='utf-8') as f:
                    custom_instructions = f.read().strip()
        except Exception as e:
            print(f"âš ï¸ system.txt ì½ê¸° ì‹¤íŒ¨ ({e})")

        # 2-2. ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°í•©
        system_prompt = f"""
        ë‹¹ì‹ ì€ ê³µì¥ ì„¤ë¹„ ë° IP ì£¼ì†Œ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ [ì°¸ê³  ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
        
        [ì¶”ê°€ ì§€ì‹œì‚¬í•­]
        {custom_instructions}
        
        [ì°¸ê³  ì •ë³´]
        {context}
        
        - [ì°¸ê³  ì •ë³´]ì— ì—†ëŠ” ë‚´ìš©ì€ "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
        - ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """

        # 3. Ollama ìš”ì²­
        payload = {
            "model": LLM_MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ],
            "stream": True # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥
        }

        print("\nğŸ¤– (ë‹µë³€ ìƒì„± ì¤‘...)\n")
        
        full_response = ""
        try:
            with requests.post(OLLAMA_URL, json=payload, stream=True) as r:
                r.raise_for_status()
                for line in r.iter_lines():
                    if line:
                        try:
                            body = json.loads(line)
                            # print(f"[DEBUG] {body}") # ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬
                            if 'error' in body:
                                print(f"âŒ Ollama ì—ëŸ¬: {body['error']}")
                                
                            if 'message' in body:
                                content = body['message'].get('content', '')
                                print(content, end="", flush=True)
                                full_response += content
                                
                            if body.get('done', False):
                                # print("\n[DEBUG] ì™„ë£Œ ì‹ í˜¸ ë°›ìŒ")
                                pass
                                
                        except json.JSONDecodeError:
                            print(f"\nâŒ JSON íŒŒì‹± ì‹¤íŒ¨: {line}")
                            
            print("\n") # ì¤„ë°”ê¿ˆ
            if not full_response:
                print("âš ï¸ ê²½ê³ : Ollamaë¡œë¶€í„° ë°›ì€ ì‘ë‹µ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
                
            return full_response
        except Exception as e:
            print(f"\nâŒ í†µì‹  ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return f"ì—ëŸ¬: {e}"

def main():
    chat_app = RAGChat()
    
    print("\nğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥)")
    print("-" * 50)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ì§ˆë¬¸: ").strip()
        except KeyboardInterrupt:
            break
            
        if not user_input:
            continue
            
        if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ', 'q']:
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        chat_app.chat(user_input)

if __name__ == "__main__":
    main()
